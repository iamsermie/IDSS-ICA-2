{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b0b591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you don't have imbalanced-learn, you can install it\n",
    "# !pip install imbalanced-learn\n",
    "\n",
    "# Import the necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import SMOTE  # Import SMOTE\n",
    "from scipy import stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f523ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset from Kaggle Stroke Prediction Dataset\n",
    "url = \"https://path-to-dataset.csv\"  # Replace with actual dataset path\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228f5fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for null values and basic info about the dataset\n",
    "df.info()\n",
    "\n",
    "# Check for missing values\n",
    "df.isnull().sum()\n",
    "\n",
    "# Basic statistics\n",
    "df.describe()\n",
    "\n",
    "# Visualize the distribution of the target variable (stroke)\n",
    "sns.countplot(data=df, x='stroke', palette='coolwarm')\n",
    "plt.title('Stroke Distribution')\n",
    "plt.show()\n",
    "\n",
    "# Visualize correlations between numeric features\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(df.corr(), annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c36de7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Z-scores for numerical columns\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "# Apply Z-score method\n",
    "z_scores = np.abs(stats.zscore(df[numeric_cols]))\n",
    "\n",
    "# Set a threshold for Z-scores to define outliers\n",
    "threshold = 3\n",
    "df_no_outliers = df[(z_scores < threshold).all(axis=1)]\n",
    "\n",
    "# Check the shape of the dataset after removing outliers\n",
    "print(f\"Shape before removing outliers: {df.shape}\")\n",
    "print(f\"Shape after removing outliers: {df_no_outliers.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c254ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the dataset without outliers for further processing\n",
    "df = df_no_outliers  # or df_no_outliers_iqr if using IQR method\n",
    "\n",
    "# Convert categorical columns to numeric using Label Encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "df['gender'] = label_encoder.fit_transform(df['gender'])\n",
    "df['ever_married'] = label_encoder.fit_transform(df['ever_married'])\n",
    "df['work_type'] = label_encoder.fit_transform(df['work_type'])\n",
    "df['Residence_type'] = label_encoder.fit_transform(df['Residence_type'])\n",
    "df['smoking_status'] = label_encoder.fit_transform(df['smoking_status'])\n",
    "\n",
    "# Define feature variables (X) and target variable (y)\n",
    "X = df.drop('stroke', axis=1)  # Features (all columns except target)\n",
    "y = df['stroke']  # Target variable (stroke)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423335f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scaling the data (important for models like SVM and Logistic Regression)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de34975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SMOTE and apply it to the training data\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# Check the class distribution after applying SMOTE\n",
    "print(f\"Original class distribution in y_train: {y_train.value_counts()}\")\n",
    "print(f\"Resampled class distribution in y_train_smote: {pd.Series(y_train_smote).value_counts()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5402cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression Model\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "log_reg.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_log_reg = log_reg.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred_log_reg))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_log_reg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214c7817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Model\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_clf.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_rf = rf_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805669d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost Model\n",
    "xgb_clf = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "xgb_clf.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_xgb = xgb_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"XGBoost Accuracy:\", accuracy_score(y_test, y_pred_xgb))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_xgb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd14b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machine Model\n",
    "svm_clf = SVC(kernel='linear', random_state=42)\n",
    "svm_clf.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_svm = svm_clf.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"SVM Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_svm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64023ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing all models based on accuracy\n",
    "models = ['Logistic Regression', 'Random Forest', 'XGBoost', 'SVM']\n",
    "accuracies = [\n",
    "    accuracy_score(y_test, y_pred_log_reg),\n",
    "    accuracy_score(y_test, y_pred_rf),\n",
    "    accuracy_score(y_test, y_pred_xgb),\n",
    "    accuracy_score(y_test, y_pred_svm)\n",
    "]\n",
    "\n",
    "# Plotting the comparison\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x=models, y=accuracies, palette='viridis')\n",
    "plt.title('Model Comparison After SMOTE')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f130257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the comparison above, choose the best model based on accuracy\n",
    "# Example: If XGBoost gave the highest accuracy, you can finalize it as the best model\n",
    "final_model = xgb_clf  # Chosen model based on previous comparison\n",
    "\n",
    "# Retrain final model with all training data\n",
    "final_model.fit(X, y)\n",
    "\n",
    "# Save the model using joblib for future use\n",
    "import joblib\n",
    "joblib.dump(final_model, 'stroke_prediction_model_with_smote.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d549fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional imports for hyperparameter tuning and ROC curve plotting\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8e737d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter grid for RandomForestClassifier\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100, 200],  # Number of trees in the forest\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],  # Number of features to consider for the best split\n",
    "    'max_depth': [None, 10, 20, 30],  # Maximum depth of the tree\n",
    "    'min_samples_split': [2, 5, 10],  # Minimum samples required to split a node\n",
    "    'min_samples_leaf': [1, 2, 4],  # Minimum number of samples required at each leaf node\n",
    "    'bootstrap': [True, False]  # Whether bootstrap samples are used when building trees\n",
    "}\n",
    "\n",
    "# Initialize the RandomForestClassifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search_rf = GridSearchCV(estimator=rf, param_grid=param_grid_rf, cv=3, n_jobs=-1, verbose=2, scoring='roc_auc')\n",
    "\n",
    "# Fit GridSearchCV to training data\n",
    "grid_search_rf.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Best hyperparameters for Random Forest\n",
    "print(\"Best parameters for Random Forest:\", grid_search_rf.best_params_)\n",
    "\n",
    "# Get the best model\n",
    "best_rf = grid_search_rf.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2035b59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter grid for XGBoost\n",
    "param_grid_xgb = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1],  # Step size at each iteration\n",
    "    'n_estimators': [50, 100, 200],  # Number of boosting rounds\n",
    "    'max_depth': [3, 6, 10],  # Maximum depth of a tree\n",
    "    'min_child_weight': [1, 5, 10],  # Minimum sum of instance weight (hessian) in a child\n",
    "    'subsample': [0.6, 0.8, 1.0],  # Fraction of samples to use for fitting trees\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0]  # Fraction of features to choose from for each tree\n",
    "}\n",
    "\n",
    "# Initialize XGBClassifier\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search_xgb = GridSearchCV(estimator=xgb, param_grid=param_grid_xgb, cv=3, n_jobs=-1, verbose=2, scoring='roc_auc')\n",
    "\n",
    "# Fit GridSearchCV to training data\n",
    "grid_search_xgb.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Best hyperparameters for XGBoost\n",
    "print(\"Best parameters for XGBoost:\", grid_search_xgb.best_params_)\n",
    "\n",
    "# Get the best model\n",
    "best_xgb = grid_search_xgb.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c027588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter grid for SVM\n",
    "param_grid_svm = {\n",
    "    'C': [0.1, 1, 10],  # Regularization parameter\n",
    "    'kernel': ['linear', 'rbf', 'poly'],  # Type of kernel to use\n",
    "    'gamma': ['scale', 'auto'],  # Kernel coefficient for ‘rbf’, ‘poly’ and ‘sigmoid’\n",
    "    'class_weight': [None, 'balanced']  # Weights for classes to deal with class imbalance\n",
    "}\n",
    "\n",
    "# Initialize SVC\n",
    "svm = SVC(probability=True, random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search_svm = GridSearchCV(estimator=svm, param_grid=param_grid_svm, cv=3, n_jobs=-1, verbose=2, scoring='roc_auc')\n",
    "\n",
    "# Fit GridSearchCV to training data\n",
    "grid_search_svm.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Best hyperparameters for SVM\n",
    "print(\"Best parameters for SVM:\", grid_search_svm.best_params_)\n",
    "\n",
    "# Get the best model\n",
    "best_svm = grid_search_svm.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c96bac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predicted probabilities for the positive class (class 1)\n",
    "y_pred_prob_rf = best_rf.predict_proba(X_test_scaled)[:, 1]\n",
    "y_pred_prob_xgb = best_xgb.predict_proba(X_test_scaled)[:, 1]\n",
    "y_pred_prob_svm = best_svm.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Calculate ROC curve for each model\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_pred_prob_rf)\n",
    "fpr_xgb, tpr_xgb, _ = roc_curve(y_test, y_pred_prob_xgb)\n",
    "fpr_svm, tpr_svm, _ = roc_curve(y_test, y_pred_prob_svm)\n",
    "\n",
    "# Calculate AUC for each model\n",
    "roc_auc_rf = auc(fpr_rf, tpr_rf)\n",
    "roc_auc_xgb = auc(fpr_xgb, tpr_xgb)\n",
    "roc_auc_svm = auc(fpr_svm, tpr_svm)\n",
    "\n",
    "# Plot ROC curves\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Plot Random Forest ROC curve\n",
    "plt.plot(fpr_rf, tpr_rf, color='blue', lw=2, label='Random Forest (AUC = %0.2f)' % roc_auc_rf)\n",
    "\n",
    "# Plot XGBoost ROC curve\n",
    "plt.plot(fpr_xgb, tpr_xgb, color='green', lw=2, label='XGBoost (AUC = %0.2f)' % roc_auc_xgb)\n",
    "\n",
    "# Plot SVM ROC curve\n",
    "plt.plot(fpr_svm, tpr_svm, color='red', lw=2, label='SVM (AUC = %0.2f)' % roc_auc_svm)\n",
    "\n",
    "# Plot the diagonal line (no skill)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9255ecd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the final AUC scores for each model\n",
    "print(\"Random Forest AUC: \", roc_auc_rf)\n",
    "print(\"XGBoost AUC: \", roc_auc_xgb)\n",
    "print(\"SVM AUC: \", roc_auc_svm)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
